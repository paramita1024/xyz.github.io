---
layout: post
title:  "Demystifying Kaggle"
date:   2019-08-15 00:00:10 -0030
categories: jekyll update
mathjax: true
---

# Content

1. TOC
{:toc}
---

Demystifying KAGGLE

# How to submit in Kaggle?


+ [link](http://joshlawman.com/submit-a-prediction-to-kaggle-for-the-first-time/)
+ [link2](https://www.kaggle.com/dansbecker/submitting-from-a-kernel/notebook)
+ [kaggle with colab](https://medium.com/@burakteke/tutorial-on-using-google-colab-for-kaggle-competition-620393c22821)

# Select the competition:
+ selecting competitions primarily to learn about a domain I don’t master

<a href="#Top" style="color:#2F4F4F;background-color: #c8f7e4;float: right;">Content</a>

----

# Useful Technique:

+ **quickly get a baseline and a submission.** This is to clear any bug or any basic misunderstanding.
+ **establish a reliable local validation setting**. The Goal is to be able to evaluate if a model is better than another model with training data, instead of relying on the public leader-board score. If you manage to get this, then you can perform as many experiments you want, and you are not bound by the 5 submissions a day limit. Submissions are only used to check that your local validation is reliable, i.e. that when your local score improves then your LB score also improves. The Basic tool for that is cross validation. Mastering cross validation, and how to define folds is a key skill. Make sure you understand when you can use a random fold split, or when you must use some stratification or some time based fold definitions.
+ **understand the metric**, and **how to approximate it via loss functions**. Sometimes it is easy, for instance using mean squared error (mse) if the metric is square root mse (rmse). Sometimes it is tricky when the metric is not differentiable, for instance when the metric is roc-auc for binary classification, or intersection over union for image segmentation.
+ Understand the importance of different algorithmic families, to see when and where to maximize the intensity (is it a linear or non-linear type of problem?)
+ Finally comes feature engineering, NN architecture choice, hyper parameter optimization, etc. Jumping to this before the preparation steps above is a loss of time.

<a href="#Top" style="color:#2F4F4F;background-color: #c8f7e4;float: right;">Content</a>

----

# Reading Material:

[marios-michailidis](https://www.linkedin.com/pulse/how-start-data-science-marios-michailidis/)

# Given the explosive growth rate of ML, How to stay up2date with the STOA?

+ A good place to get alerts on the interesting material is the [KaggleNoobs](https://kagglenoobs.herokuapp.com/) slack team

<a href="#Top" style="color:#2F4F4F;background-color: #c8f7e4;float: right;">Content</a>

----

# Other Best Practices:

+ Understand the problem well.
+ **Discipline**; To have a well-thorough and documented approach that you follow strictly and defines all the modelling process/framework from how you cross-validate, select models, avoids overfitting (which requires a lot of …discipline).
+ Allow room to **try problem-specific things** or new approaches within that framework. For example, unless you use deep learning for image classification, you are not likely to go very far.
+ **Ensembling** (as in combing many different algorithms/approaches to get a better score).
+ started asking people very noob questions to clarify and get a solid understanding of the underlying concepts. Since then, the journey has been quite interesting.

----

<a href="#Top" style="color:#023628;background-color: #f7d06a;float: right;">Back to Top</a>