---
layout: post
title:  "Responsible AI"
date:   2021-02-06 00:00:10 -0030
categories: responsibleai
mathjax: true
---



# Content

1. TOC
{:toc}

---

# Shapely Values

<center>
<figure class="video_container">
  <iframe src="https://www.youtube.com/embed/B-c8tIgchu0" frameborder="0" allowfullscreen="true" width="100%" height="300"> </iframe>
</figure>
</center>

_*In case the above link is broken, click [here](https://www.youtube.com/embed/B-c8tIgchu0)_


# Asymmetric Shapely Values:

The Shapley framework for explainability has strength in its general applicability combined with its precise, rigorous foundation: it provides a common, model-agnostic language for AI explainability and uniquely satisfies a set of intuitive mathematical axioms.

**Issues:** Shapley values are too restrictive in one significant regard: they ignore all causal structure in the data.

**Solution:**  Asymmetric Shapley values (ASVs), which are rigorously founded on a set of axioms, applicable to any AI system, and flexible enough to incorporate any causal structure known to be respected by the data. We demonstrate that ASVs can (i) improve model explanations by incorporating causal information, (ii) provide an unambiguous test for unfair discrimination in model predictions, (iii) enable sequentially incremental explanations in time-series models, and (iv) support feature-selection studies without the need for model retraining. 

- [Paper](https://arxiv.org/abs/1910.06358)
- [Slide 35-37](https://www.stateof.ai/)

----

# :star: Uncertainty toolbox

- [github](https://github.com/uncertainty-toolbox/uncertainty-toolbox)

----

# Bias, Fairness and Explainability â€” steps towards building Responsible AI

- [Blog](https://medium.com/walmartglobaltech/bias-fairness-and-explainability-steps-towards-building-responsible-ai-dc735b06279)

----